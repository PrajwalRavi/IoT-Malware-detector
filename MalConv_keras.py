import pandas as pd
from keras import optimizers
from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
from keras.layers import *
from  keras.layers import Conv1D
from keras.layers import multiply
from  keras.models import Input
from keras.models import Model
from warnings import filterwarnings
import warnings

filterwarnings('ignore')
warnings.simplefilter(action='ignore', category=FutureWarning)

## LOAD DATASETS PROPERLY, X AND Y.


x = 116356
# x = Embedding Comes here
main_input = Input(shape=(None, x))

conv1 = Conv1D(128, 500, padding='same')(main_input)
conv2 = Conv1D(128, 500, padding='same')(main_input)
# concat =  Concatenate()([conv1,conv2])
concat = multiply([conv1, conv2])
y = MaxPooling1D()(concat)

output = Dense(output_dim=1, activation='sigmoid', init='lecun_uniform', kernel_regularizer=regularizers.l2(0.0001))(y)
model = Model(inputs=[main_input], outputs=[output])

adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)
model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])
# model.load_weights('output.hdf5')
print(model.summary())
X = pd.read_csv("benign_csv.csv", error_bad_lines=False)
# X_valid = pd.read_csv("benign_csv.csv", error_bad_lines=False).loc[500:, :]
X.fillna(0, axis=1, inplace=True)
# X_valid.fillna(0, axis=1, inplace=True)

y_valid = np.array([1 for i in range(X_valid.shape[0])])
t = np.random.choice([0, 1], size=X.shape[0])
reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)
checkpoint = ModelCheckpoint(filepath='check', verbose=1, save_best_only=True)

history = model.fit(x=X.values.reshape(X.shape[0], 1, X.shape[1]), y=t.reshape(X.shape[0], 1, 1), batch_size=32,
                    validation_split=0.2,
                    epochs=200,
                    callbacks=[reducelr, checkpoint], verbose=2)

y_pred = model.predict(X_valid)
y_pred = pd.DataFrame(y_pred)
y_pred1 = y_pred.values
print(model.summary())
